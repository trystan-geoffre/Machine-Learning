<h1 align="center">Machine Learning</h1>

<br>

Welcome to my repository dedicated to the captivating realm of Machine Learning!

<br>

<h2 align="center">üåÖ Journey Highlights üåÖ</h2>
<p>


---

Before diving into the projects, you'll find a comprehensive list of Models and data cleaning Methods

<br>

<details>
  <h2 align="center"> üìö Models & Methods üìö </h2>
  
  <summary> üìö Models & Methods üìö</summary> 
<p>

<h3>Models</h3>

**Support Vector Machines (SVM):** 

**Logistic Regression: Lasso | Ridge |  Elasitc Net-Reglarization** 

**GradiantBoost:** 

**GridSearchCV:** 

**Support Vector Machines (SVM):** 

<h3>Methods</h3>

**One Hot Encoder (OHE):** 

**Principal Component Analysis (PCA):** 

**:** 
</p>
  <br>
</details>

<br>

<h2 align="center">üîé Repository Overview üîç</h2>
<br>
This repository is a testament to my exploration and experimentation within the domain of Deep Learning. It is divided into two primary sections:

<br>


<details>
  <h2 align="center"> Logistic Regression using Lasso | Ridge | Elasitc Net-Reglarization </h2>
  
  <summary> Logistic Regression using Lasso | Ridge | Elasitc Net-Reglarization </summary> 

  <p>
The provided code fits Logistic Regression models with different regularization techniques on a breast cancer dataset. The L1-regularized model (Lasso), L2-regularized model (Ridge), and elastic net-regularized model are trained on a standardized training set. The models are then evaluated using a comprehensive evaluation function, including metrics such as confusion matrix, accuracy, precision, recall, F1 score, ROC curve, and the distribution of predicted probabilities. Additionally, the code extracts and analyzes the coefficients of the features from each model, providing insights into the importance of individual features in making predictions. The elastic net model, which combines L1 and L2 regularization, aims to strike a balance between feature selection and regularization. The overall approach demonstrates a thorough analysis of logistic regression models with different regularization techniques applied to a breast cancer classification task.
<a href="https://github.com/trystan-geoffre/Machine-Learning/blob/master/Python/LASSO(L1)%20%7C%C2%A0Ridge(L2)%20%7C%20Elastic%20Net%20Regularization.ipynb"> Code Link</a>
  </p>
  <br>
</details>

<br>

<details>
  <h2 align="center"> GradiantBoost & GridSearchCV </h2>
  
  <summary> GradiantBoost & GridSearchCV </summary> 

  <p>
The code begins by loading the Boston Housing dataset and organizing its features and target variable into Pandas DataFrames. Subsequently, it splits the dataset into training and testing sets using the train_test_split function from scikit-learn. Then, a Gradient Boosting Regressor model is created and trained on the training set. Predictions are made on the test set, and the R-squared score is calculated to evaluate the model's performance.
Following this, the code visualizes the feature importances using a horizontal bar chart. It normalizes and sorts the importances before plotting. Finally, hyperparameter tuning is performed using GridSearchCV to optimize the Gradient Boosting Regressor model. The grid includes different combinations of learning rates and numbers of estimators. The best hyperparameters and their corresponding R-squared score on the training set are printed, providing insights into the optimal configuration for the model. <a href="https://github.com/trystan-geoffre/Machine-Learning/blob/master/Python/GradiantBoost%20%26%20GridSearchCV.ipynb"> Code Link</a>
  </p>
  <br>
</details>

<br>


<details>
  <h2 align="center"> Support Vector Machines (SVM) & One Hot Encoder (OHE) & Principal Component Analysis (PCA) </h2>
  
  <summary> Support Vector Machines (SVM) & One Hot Encoder (OHE) & Principal Component Analysis (PCA) </summary> 

  <p>
The code reads data from an Excel file into a Pandas DataFrame and performs several data processing steps. It renames columns, drops unnecessary columns, and conducts exploratory data analysis. It handles missing values and class imbalances through resampling. The code then prepares the data for modeling by encoding categorical features, splitting into training and testing sets, and scaling the features.

The Support Vector Classification (SVC) model is trained, and hyperparameter tuning is performed using grid search. The tuned model is then evaluated on the test set. Principal Component Analysis (PCA) is applied to reduce dimensionality, and the first two principal components are used to train an SVM model. The decision surface of the model is visualized in a 2D plot.

Overall, the code covers data preprocessing, model training and tuning, dimensionality reduction, and visualization to analyze the performance of an SVM classifier on credit card default prediction.
<a href="https://github.com/trystan-geoffre/Machine-Learning/blob/master/Python/SVM/Support%20Vector%20Machines%20(SVM)%20%26%20One%20Hot%20Encoder%20(OHE)%20%26%20Principal%20Component%20Analysis%20(PCA).ipynb"> Code Link</a>
  </p>
  <br>
</details>

<br>


<details>
  <h2 align="center"> Case Study 1 & 2</h2>
  
  <summary>  </summary> 

  <p>
In the context of a case study focused on data manipulation, the two examples illustrate common practices in data cleaning and enhancement. For both, the code addresses fundamental tasks such as handling missing values, eliminating irrelevant rows, and removing duplicate entries. It also encompasses actions like altering data types, concatenating information, and rectifying spelling errors. <a href="https://github.com/trystan-geoffre/Machine-Learning/blob/master/Python/Case%20Study%201.ipynb"> Code Link for Case Study 1</a>

For the second case, the code expands its scope to advanced operations. Apart from the foundational cleaning steps, it involves sorting data for improved organization, ranking data to identify patterns or outliers, extracting insightful information to address specific queries, and employing data visualization techniques for enhanced comprehension.  <a href="https://github.com/trystan-geoffre/Machine-Learning/blob/master/Python/Case%20Study%202.ipynb"> Code Link</a>
  </p>
  <br>
</details>

<br>


<details>
  <h2 align="center">  </h2>
  
  <summary>  </summary> 

  <p>

<a href=""> Code Link</a>
  </p>
  <br>
</details>

<br>


<details>
  <h2 align="center">  </h2>
  
  <summary>  </summary> 

  <p>

<a href=""> Code Link</a>
  </p>
  <br>
</details>

<br>


<details>
  <h2 align="center">  </h2>
  
  <summary>  </summary> 

  <p>

<a href=""> Code Link</a>
  </p>
  <br>
</details>

<br>

